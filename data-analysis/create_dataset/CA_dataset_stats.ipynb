{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the C -> A dataset to be used by the fine-tuned BERT classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions and thoughts\n",
    "- Tutorial: https://huggingface.co/docs/transformers/custom_datasets\n",
    "- Context texts must be limited to 512 tokens (Limit for BERT model)\n",
    "- When labeling the dataset, should the labels be start, end, or start and inside? In other projects (with answer extraction) it seems they use start, end..\n",
    "- Another option is to insert a higlight token around the sentence containing the answer, and then append the answers after a [SEP] token. As in: \n",
    "- There are multiple answer spans in the same context text.. Should those be labeled jointly? / should I have multiple instances of the same texts?\n",
    "- My idea is to use the original text, no stopword removal or lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary library imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data imports, to be combined into the final datastructure\n",
    "labeled_df = pd.read_pickle(\"./data/labeled_CA_training_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num labels:  210487\n",
      "num zeros:  204714\n",
      "num ones:  1453\n",
      "num twos:  4320\n",
      "[0.00672723 0.9478027  0.31878642]\n"
     ]
    }
   ],
   "source": [
    "# compute the class weights to use in the training of the C -> A model (to account for the scarse dataset)\n",
    "num_labels = 0\n",
    "num_zeros = 0\n",
    "num_ones = 0\n",
    "num_twos = 0\n",
    "for idx, point in labeled_df.iterrows():\n",
    "    labels = point['labels']\n",
    "    for label in labels:\n",
    "        num_labels += 1\n",
    "        if label == 0:\n",
    "            num_zeros += 1\n",
    "        elif label == 1:\n",
    "            num_ones += 1\n",
    "        else:\n",
    "            num_twos += 1\n",
    "print('num labels: ', num_labels)\n",
    "print('num zeros: ', num_zeros)\n",
    "print('num ones: ', num_ones)\n",
    "print('num twos: ', num_twos)\n",
    "\n",
    "weights = np.array([1/num_zeros, 1/num_ones, 1/num_twos])\n",
    "norm = np.linalg.norm(weights)\n",
    "normal_array = weights/norm\n",
    "print(normal_array)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de4ab37d9aa598fa28430b4c5abb54602406a240d03eddec7af88b85de3986f7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('dp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
