{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the C -> A dataset to be used by the fine-tuned BERT classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions and thoughts\n",
    "- Tutorial: https://huggingface.co/docs/transformers/custom_datasets\n",
    "- Context texts must be limited to 512 tokens (Limit for BERT model)\n",
    "- When labeling the dataset, should the labels be start, end, or start and inside? In other projects (with answer extraction) it seems they use start, end..\n",
    "- Another option is to insert a higlight token around the sentence containing the answer, and then append the answers after a [SEP] token. As in: \n",
    "- There are multiple answer spans in the same context text.. Should those be labeled jointly? / should I have multiple instances of the same texts?\n",
    "- My idea is to use the original text, no stopword removal or lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data imports, to be combined into the final datastructure\n",
    "CA_df = pd.read_pickle(\"./data/labeled_CA_training_data.pkl\")\n",
    "CAR_df = pd.read_pickle(\"./data/labeled_CAR_data_train.pkl\")\n",
    "CRA_df = pd.read_pickle(\"./data/labeled_CRA_data_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the class weights to use in the training of the C -> A model (to account for the scarse dataset)\n",
    "# idea for how to scale weights:\n",
    "# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#calculate_class_weights\n",
    "# https://medium.com/gumgum-tech/handling-class-imbalance-by-introducing-sample-weighting-in-the-loss-function-3bdebd8203b4\n",
    "\n",
    "def get_class_distribution(labeled_df):\n",
    "    nr_classes = 3\n",
    "    num_labels = 0\n",
    "    num_zeros = 0\n",
    "    num_ones = 0\n",
    "    num_twos = 0\n",
    "    for idx, point in labeled_df.iterrows():\n",
    "        labels = point['labels']\n",
    "        for label in labels:\n",
    "            num_labels += 1\n",
    "            if label == 0:\n",
    "                num_zeros += 1\n",
    "            elif label == 1:\n",
    "                num_ones += 1\n",
    "            else:\n",
    "                num_twos += 1\n",
    "    print('num labels: ', num_labels)\n",
    "    print('num zeros: ', num_zeros)\n",
    "    print('num ones: ', num_ones)\n",
    "    print('num twos: ', num_twos)\n",
    "\n",
    "    ins_weights = np.array([1/num_zeros, 1/num_ones, 1/num_twos]) * (num_labels/2)\n",
    "    ins_weights_raw = np.array([1/num_zeros, 1/num_ones, 1/num_twos])\n",
    "    ins_weights_norm = ins_weights_raw / np.sum(ins_weights_raw) * nr_classes\n",
    "\n",
    "    isns_weights = np.array([1/math.sqrt(num_zeros), 1/math.sqrt(num_ones), 1/math.sqrt(num_twos)]) * (math.sqrt(num_labels/2))\n",
    "    isns_weights_raw = np.array([1/math.sqrt(num_zeros), 1/math.sqrt(num_ones), 1/math.sqrt(num_twos)])\n",
    "    isns_weights_norm = isns_weights_raw / np.sum(isns_weights_raw) * nr_classes\n",
    "\n",
    "    # ENS\n",
    "    B = 0.99999\n",
    "    samples_per_class = [num_zeros, num_ones, num_twos]\n",
    "    E_nc = (1.0 - np.power(B, samples_per_class)) / (1.0 - B)\n",
    "    w = 1/E_nc\n",
    "    # normalize:\n",
    "    w = w / np.sum(w) * nr_classes\n",
    "\n",
    "    # norm = np.linalg.norm(weights)\n",
    "    # normal_array = weights/norm\n",
    "    print('INS: ',ins_weights)\n",
    "    print('INS, norm: ',ins_weights_norm)\n",
    "    print('ISNS: ',isns_weights)\n",
    "    print('ISNS, norm: ',isns_weights_norm)\n",
    "    print('ENS: ',w)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num labels:  210487\n",
      "num zeros:  204714\n",
      "num ones:  1453\n",
      "num twos:  4320\n",
      "INS:  [ 0.51410016 72.43186511 24.3619213 ]\n",
      "INS, norm:  [0.0158497  2.23307281 0.7510775 ]\n",
      "ISNS:  [0.71700778 8.51069122 4.93577971]\n",
      "ISNS, norm:  [0.15187112 1.80266968 1.0454592 ]\n",
      "ENS:  [0.90404534 1.17975022 0.91620444]\n"
     ]
    }
   ],
   "source": [
    "get_class_distribution(CA_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num labels:  729271\n",
      "num zeros:  669463\n",
      "num ones:  3313\n",
      "num twos:  56495\n",
      "INS:  [  0.54466864 110.06202837   6.45429684]\n",
      "INS, norm:  [0.01395859 2.82063285 0.16540856]\n",
      "ISNS:  [ 0.73801669 10.49104515  2.54053082]\n",
      "ISNS, norm:  [0.16079271 2.28569837 0.55350893]\n",
      "ENS:  [0.08833199 2.70726576 0.20440225]\n"
     ]
    }
   ],
   "source": [
    "get_class_distribution(CAR_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num labels:  604604\n",
      "num zeros:  600883\n",
      "num ones:  940\n",
      "num twos:  2781\n",
      "INS:  [  0.50309628 321.59787234 108.70262496]\n",
      "INS, norm:  [0.00350343 2.23952082 0.75697575]\n",
      "ISNS:  [ 0.7092928 17.9331501 10.4260551]\n",
      "ISNS, norm:  [0.07320221 1.85078191 1.07601587]\n",
      "ENS:  [0.184452   2.05582795 0.75972005]\n"
     ]
    }
   ],
   "source": [
    "get_class_distribution(CRA_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de4ab37d9aa598fa28430b4c5abb54602406a240d03eddec7af88b85de3986f7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('dp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
