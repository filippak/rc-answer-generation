{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the C -> A dataset to be used by the fine-tuned BERT classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions and thoughts\n",
    "- Tutorial: https://huggingface.co/docs/transformers/custom_datasets\n",
    "- Context texts must be limited to 512 tokens (Limit for BERT model)\n",
    "- When labeling the dataset, should the labels be start, end, or start and inside? In other projects (with answer extraction) it seems they use start, end..\n",
    "- Another option is to insert a higlight token around the sentence containing the answer, and then append the answers after a [SEP] token. As in: \n",
    "- There are multiple answer spans in the same context text.. Should those be labeled jointly? / should I have multiple instances of the same texts?\n",
    "- My idea is to use the original text, no stopword removal or lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data imports, to be combined into the final datastructure\n",
    "CA_df = pd.read_pickle(\"./data/CA/labeled_CA_data_train.pkl\")\n",
    "CAR_df = pd.read_pickle(\"./data/CAR/labeled_CAR_data_train.pkl\")\n",
    "CAR_sent_class_df = pd.read_pickle(\"./data/CAR_classification/labeled_CAR_data_train.pkl\")\n",
    "CRA_df = pd.read_pickle(\"./data/CRA/labeled_CRA_data_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the class weights to use in the training of the C -> A model (to account for the scarse dataset)\n",
    "# idea for how to scale weights:\n",
    "# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#calculate_class_weights\n",
    "# https://medium.com/gumgum-tech/handling-class-imbalance-by-introducing-sample-weighting-in-the-loss-function-3bdebd8203b4\n",
    "\n",
    "def get_class_distribution(labeled_df, is_sent_class):\n",
    "    if is_sent_class:\n",
    "        nr_classes = 2\n",
    "    else:\n",
    "        nr_classes = 3\n",
    "    counts = np.zeros(nr_classes)\n",
    "    for idx, point in labeled_df.iterrows():\n",
    "        if 'labels' in point.keys():\n",
    "            labels = point['labels']\n",
    "            for label in labels:\n",
    "                counts[int(label)] += 1\n",
    "\n",
    "\n",
    "        else:\n",
    "            label = point['label']\n",
    "            counts[int(label)] += 1\n",
    "\n",
    "    num_labels = np.sum(counts)\n",
    "    ins_weights = (num_labels/2) / counts\n",
    "    ins_weights_raw = 1/ counts\n",
    "    ins_weights_norm = ins_weights_raw / np.sum(ins_weights_raw) * nr_classes\n",
    "    # ins_weights = np.array([1/num_zeros, 1/num_ones, 1/num_twos]) * (num_labels/2)\n",
    "    # ins_weights_raw = np.array([1/num_zeros, 1/num_ones, 1/num_twos])\n",
    "    # ins_weights_norm = ins_weights_raw / np.sum(ins_weights_raw) * nr_classes\n",
    "    isns_weights_raw = 1 / np.sqrt(counts)\n",
    "    isns_weights = isns_weights_raw * (math.sqrt(num_labels/2))\n",
    "    # isns_weights = np.array([1/math.sqrt(num_zeros), 1/math.sqrt(num_ones), 1/math.sqrt(num_twos)]) * (math.sqrt(num_labels/2))\n",
    "    # isns_weights_raw = np.array([1/math.sqrt(num_zeros), 1/math.sqrt(num_ones), 1/math.sqrt(num_twos)])\n",
    "    isns_weights_norm = isns_weights_raw / np.sum(isns_weights_raw) * nr_classes\n",
    "\n",
    "    # ENS\n",
    "    B = 0.9999\n",
    "    E_nc = (1.0 - np.power(B, counts)) / (1.0 - B)\n",
    "    w = 1/E_nc\n",
    "    # normalize:\n",
    "    w = w / np.sum(w) * nr_classes\n",
    "\n",
    "    # norm = np.linalg.norm(weights)\n",
    "    # normal_array = weights/norm\n",
    "    print('INS: ',ins_weights)\n",
    "    print('INS, norm: ',ins_weights_norm)\n",
    "    print('ISNS: ',isns_weights)\n",
    "    print('ISNS, norm: ',isns_weights_norm)\n",
    "    print('ENS: ',w)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INS:  [ 0.51416189 72.53486395 24.2126029 ]\n",
      "INS, norm:  [0.01585914 2.23731182 0.74682904]\n",
      "ISNS:  [0.71705083 8.51674022 4.92063034]\n",
      "ISNS, norm:  [0.15197742 1.80510527 1.04291731]\n",
      "ENS:  [0.22420819 2.02073775 0.75505406]\n"
     ]
    }
   ],
   "source": [
    "get_class_distribution(CA_df, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INS:  [  0.54466864 110.06202837   6.45429684]\n",
      "INS, norm:  [0.01395859 2.82063285 0.16540856]\n",
      "ISNS:  [ 0.73801669 10.49104515  2.54053082]\n",
      "ISNS, norm:  [0.16079271 2.28569837 0.55350893]\n",
      "ENS:  [0.54060372 1.91688386 0.54251243]\n"
     ]
    }
   ],
   "source": [
    "get_class_distribution(CAR_df, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INS:  [  0.5034363  289.26768868  98.09344175]\n",
      "INS, norm:  [0.00389391 2.23738681 0.75871928]\n",
      "ISNS:  [ 0.70953245 17.00787137  9.90421333]\n",
      "ISNS, norm:  [0.07706273 1.84723486 1.0757024 ]\n",
      "ENS:  [0.23868534 1.99823542 0.76307924]\n"
     ]
    }
   ],
   "source": [
    "get_class_distribution(CRA_df, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INS:  [0.54331738 6.27135527        inf]\n",
      "INS, norm:  [ 0.  0. nan]\n",
      "ISNS:  [0.73710066 2.50426741        inf]\n",
      "ISNS, norm:  [ 0.  0. nan]\n",
      "ENS:  [ 0.  0. nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippakarrfelt/opt/anaconda3/envs/dp/lib/python3.7/site-packages/ipykernel_launcher.py:24: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/Users/filippakarrfelt/opt/anaconda3/envs/dp/lib/python3.7/site-packages/ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/Users/filippakarrfelt/opt/anaconda3/envs/dp/lib/python3.7/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Users/filippakarrfelt/opt/anaconda3/envs/dp/lib/python3.7/site-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/Users/filippakarrfelt/opt/anaconda3/envs/dp/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Users/filippakarrfelt/opt/anaconda3/envs/dp/lib/python3.7/site-packages/ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/Users/filippakarrfelt/opt/anaconda3/envs/dp/lib/python3.7/site-packages/ipykernel_launcher.py:41: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "get_class_distribution(CAR_sent_class_df, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de4ab37d9aa598fa28430b4c5abb54602406a240d03eddec7af88b85de3986f7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('dp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
