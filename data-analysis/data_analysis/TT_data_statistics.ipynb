{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import codecs\n",
    "import argparse\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional num data points:  733\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(codecs.open('../../data/data_cleaned/qa_part3_clean.json', 'r', 'utf-8'), orient='split')\n",
    "print('Additional num data points: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of context texts:  115\n",
      "mean number of questions:  6.373913043478261\n",
      "std:  5.426923012512976\n"
     ]
    }
   ],
   "source": [
    "def count_questions_per_answers(df):\n",
    "    context_count_dict = {}\n",
    "    context_length_dict = {}\n",
    "    for index, row in df.iterrows():\n",
    "        context = row['context']\n",
    "        if context in context_count_dict:\n",
    "            context_count_dict[context] += 1\n",
    "        else:\n",
    "            context_length_dict[context] = len(context)\n",
    "            context_count_dict[context] = 1\n",
    "    return context_count_dict, context_length_dict\n",
    "\n",
    "c_count_dict, c_length_dict = count_questions_per_answers(df)\n",
    "print('Number of context texts: ', len(c_count_dict.keys()))\n",
    "num_qs = list(c_count_dict.values())\n",
    "print('mean number of questions: ', np.mean(num_qs))\n",
    "print('std: ', np.std(num_qs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional num data points:  962\n",
      "Number of context texts:  434\n",
      "mean number of questions:  2.216589861751152\n",
      "std:  1.446145801678684\n"
     ]
    }
   ],
   "source": [
    "df_o = pd.read_json(codecs.open('../../data/data_cleaned/training_clean.json', 'r', 'utf-8'), orient='split')\n",
    "print('Additional num data points: ', len(df_o))\n",
    "\n",
    "c_count_dict_o, c_length_dict_o = count_questions_per_answers(df_o)\n",
    "print('Number of context texts: ', len(c_count_dict_o.keys()))\n",
    "num_qs_o = list(c_count_dict_o.values())\n",
    "print('mean number of questions: ', np.mean(num_qs_o))\n",
    "print('std: ', np.std(num_qs_o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of context texts:  453\n",
      "mean number of questions:  3.1324503311258276\n",
      "std:  3.3322469466287563\n"
     ]
    }
   ],
   "source": [
    "# statistics for the test dataset\n",
    "df = pd.read_pickle(\"../create_dataset/data/labeled_data_train.pkl\")\n",
    "df.head()\n",
    "\n",
    "c_count_dict, c_length_dict = count_questions_per_answers(df)\n",
    "print('Number of context texts: ', len(c_count_dict.keys()))\n",
    "num_qs = list(c_count_dict.values())\n",
    "print('mean number of questions: ', np.mean(num_qs))\n",
    "print('std: ', np.std(num_qs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of context texts:  104\n",
      "mean number of questions:  3.0288461538461537\n",
      "std:  2.7750839584292506\n"
     ]
    }
   ],
   "source": [
    "df_eval = pd.read_pickle(\"../create_dataset/data/labeled_data_eval.pkl\")\n",
    "c_count_dict, c_length_dict = count_questions_per_answers(df_eval)\n",
    "print('Number of context texts: ', len(c_count_dict.keys()))\n",
    "num_qs = list(c_count_dict.values())\n",
    "print('mean number of questions: ', np.mean(num_qs))\n",
    "print('std: ', np.std(num_qs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of context texts:  41\n",
      "mean number of questions:  1.951219512195122\n",
      "std:  1.0347904114925084\n"
     ]
    }
   ],
   "source": [
    "# statistics for the test\n",
    "df = pd.read_pickle('../data_frames/parsed_answer_data/df_test.pkl')\n",
    "\n",
    "c_count_dict, c_length_dict = count_questions_per_answers(df)\n",
    "print('Number of context texts: ', len(c_count_dict.keys()))\n",
    "num_qs = list(c_count_dict.values())\n",
    "print('mean number of questions: ', np.mean(num_qs))\n",
    "print('std: ', np.std(num_qs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de4ab37d9aa598fa28430b4c5abb54602406a240d03eddec7af88b85de3986f7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('dp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
